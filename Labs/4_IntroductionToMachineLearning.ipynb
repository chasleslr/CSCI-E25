{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da79ae42",
   "metadata": {},
   "source": [
    "# CSCI E-25    \n",
    "## Introduction to Machine Learning and Linear Models\n",
    "\n",
    "### Steve Elston   \n",
    "\n",
    "## Introduction to Linear Models \n",
    "\n",
    "The concept of the linear model is the basis of many statistical and machine learning models. Further, an understanding of linear models is a good basis for understand many other types of statistical and machine learning models.   \n",
    "\n",
    "In this lesson we will focus on regression models, but the lessons drawn from this discussion can be applied to many other types of models. By developing an understanding of linear regression, you are building a foundation to understand many other machine learning models. Nearly all machine learning methods suffer from the same problems, including over-fitting and mathematically unstable fitting methods. Understanding these problems in the linear regression context will help you work with other machine learning models.     \n",
    "\n",
    "The method of regression is one of the oldest and most widely used analytics methods. The goal of regression is to produce a model that represents the **best fit** to some observed data. Typically the model is a function describing some type of curve (lines, parabolas, etc.) that is determined by a set of parameters (e.g., slope and intercept). *Best fit* means that there is an optimal set of parameters which minimize an error criteria we choose.     \n",
    "\n",
    "Many machine learning models, including some of the latest deep learning methods, are a form of regression. **Linear regression** is the foundational form of regression. Linear regression minimizes squared error of the predictions of the dependent variable using the values of the independent variables. This approach is know as the **method of least squares**.   \n",
    "\n",
    "Regression models attempt to predict the value of one variable using the values of other variable. Unfortunately, the terminology used for these variables is not consistent across authors, statistical software packages, and application domains. The table below list some, but by no means all of the terms used for these variables. \n",
    "\n",
    "### Confusing terminology \n",
    "\n",
    "Given that linear models have been developed in many areas of a long period of times, different terminology has developed for the same things. For people trying to learn the subject this differing terminology is confusing and seemingly conflicting.    \n",
    "\n",
    "The main division in terminology arises from different communities within statistics and machine learning. The table below shows some of the different terms commonly used in the two lineages:       \n",
    "\n",
    "| Machine Learning Terminology | Statistical Terminology          |\n",
    "|:---------------------------|:------------------------------|\n",
    "| Regression vs classification   | Continuous numeric vs categorical response      |\n",
    "| Learning algorithm or model    | Model                                |\n",
    "| Features                       | Predictor, exogenous, or independent variables   |\n",
    "| Training                       | Fitting                              |\n",
    "| Trained model                  | Fitted model                         |\n",
    "| Supervised learning            | Predictive modeling      \n",
    "\n",
    "For the specific case of regression there are further differences in terminology. These arise not just between the statistical and machine learning communities. One difference in terminology is the naming of the variables used in regression and other machine learning models. The table below outlines some of these differences:          \n",
    "\n",
    "Predicted Variable | Variables Used to Predict    \n",
    ":----------------------- | :------------------------------     \n",
    " y | x   \n",
    " Dependent | Independent    \n",
    " Endogenous | Exogenous    \n",
    " Response | Predictor    \n",
    " Response | Explanatory    \n",
    " Label | Feature    \n",
    " Regressand | Regressors    \n",
    " Outcome | Design   \n",
    " Left Hand Side | Right Hand Side     \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b078e",
   "metadata": {},
   "source": [
    "## Introduction to Theory of Linear Regression\n",
    "\n",
    "We will focus on the theory of **linear models**, which are foundational. Key properties of linear models include:\n",
    "- Derived with linear algebra.\n",
    "- Include any model **linear in coefficients**, including polynomials, splines, Gaussian kernels and many other nonlinear function.    \n",
    "- Understanding linear models is basis for understanding behavior many other statistical or machine learning models.\n",
    "- Basis of many time series models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a6e5b",
   "metadata": {},
   "source": [
    "### Linear model of a strait line\n",
    "\n",
    "Let's have a look at the simple case of a regression model for a straight line. For this example we will work with single regression with one feature and one label. The data are in the form of some number of values pairs, $\\{x_i,y_i \\}$. \n",
    "\n",
    "The goal of this regression model is to find a straight that best fits the observed data. We can define the line by two coefficients or **parameters**, the **slope** and the **intercept**. A general representation of this parameterization of a straight line is illustrated in the figure below.\n",
    "\n",
    "<img src=\"img/ymxb.jpg\" alt=\"y_equals_mx_plus_b\" style=\"width: 450px;\"/>\n",
    "<center>**Single regression model**</center>\n",
    "\n",
    "Where,  \n",
    "\n",
    "\\begin{align}\n",
    "m &= slope = \\frac{rise}{run} = \\frac{\\delta y}{\\delta x}\\\\\n",
    "and\\\\\n",
    "y &= b\\ at\\ x = 0\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "For each of the pairs of observed values, ${x_i,y_i}$, we can write the equation for the line with the errors as:\n",
    "\n",
    "\\begin{align}\n",
    "y_i &= mx_i + b + \\epsilon_i \\\\\n",
    "where \\\\\n",
    "\\epsilon_i &= error\n",
    "\\end{align}\n",
    "\n",
    "We can visualize these errors as shown in the figure below.\n",
    "\n",
    "<img src=\"img/LSRegression.jpg\" alt=\"LSRegression\" style=\"width: 450px;\"/>\n",
    "<center>Example of least squares regression with errors shown as vertical lines</center>\n",
    "\n",
    "We want to solve for $m$ and $b$ by minimizing the error, $\\epsilon_i$. We call this **least squares regression** problem.\n",
    "\n",
    "$$min \\Sigma_i \\epsilon^2 = min \\Sigma_i{ (y_i - (mx_i + b))^2}$$\n",
    "\n",
    "There are lots of computationally efficient algorithms for finding minimums of equations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab2af0d",
   "metadata": {},
   "source": [
    "## Linear regression assumptions\n",
    "\n",
    "Now we should discuss a few key assumptions of linear regression. Keep these points in mind whenever you use these models. \n",
    "\n",
    "1. There is a **linear relationship** between dependent variable and the **coefficients** of the independent variables. This does not mean the function approximation used must be linear. Only that the model must be linear in the coefficients. \n",
    "2. Measurement error is independent and random. Technically, we say that the error is **independent identical distribution, or iid**.\n",
    "3. Errors arise from the dependent variable only. Other models, such as complete regression, must be used if there are errors in the independent variable. \n",
    "The diagram below illustrates the iid errors for the dependent variable only.\n",
    "\n",
    "![](img/IndependentErrors.jpg)\n",
    "\n",
    "4. There is no **multicolinearity** between the features or independent variables. In other words, there is no significant correlation between the features.\n",
    "5. The **residuals** are **homoscedastic** (constant variance).  In other words, the errors are the same across all values of the independent variables. We have explore this concept further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1958c12",
   "metadata": {},
   "source": [
    "## Load and Prepare MNIST image Data    \n",
    "\n",
    "We will now work through an example of using a linear classifier for image classification. For this example we will use the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) image data set. MNIST is a commonly used benchmark standard data set used for image classification research. The dataset is comprised of $28 \\times 28$ images of hand written digits in the set $[0-9$. There are 60,000 training images and labels and 10,000 test images and labels.            \n",
    "\n",
    "To get started, execute the code in the cell below to import the packages you will require for this example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import keras.utils.np_utils as ku\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import skimage.feature as feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef587d6",
   "metadata": {},
   "source": [
    "The MNIST dataset is built into Keras with the training and test subsets of images and labels returned in lists. Execute the code in the cell below to load these subsets. \n",
    "\n",
    "> **Note:** The MNIST data contain simple images of hand written digits. These images are properly cropped and have nearly binary light (digit) and dark (background region) areas. No significant adjustment or transformation of these images is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train_images, train_labels), (raw_test_images, test_labels) = mnist.load_data()\n",
    "print(raw_train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5d197",
   "metadata": {},
   "source": [
    "> **Exercise 4-1:** It is useful to get a feeling for what this image data really looks like. On a $5 \\times 5$ grid display the first 25 gray-scale training images. Give each image display a title with the label for that image or case. *Hint,* use a large display area.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89055a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf47bb",
   "metadata": {},
   "source": [
    "> Examine the images and the labels. What problems can you foresee when a machine learning algorithm attempts to learn to classify the digits shown in these images? Your answer need only be 1 to 3 well chosen sentences.             \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c34ec",
   "metadata": {},
   "source": [
    "> **Answer:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7aad72",
   "metadata": {},
   "source": [
    "In order to perform machine learning with image data you must transform the data to a structure with all the **features** for each image in one row of a **model matrix**. The linear model can then be written:      \n",
    "\n",
    "$$X b = y$$\n",
    "\n",
    "where:    \n",
    "$X$ is the model matrix with the features values for each image in the rows.    \n",
    "$b$ is the coefficient vector, with one coefficient per feature.   \n",
    "$y$ is the vector of the **labels** which encode the categories of the objects in the images.    \n",
    "\n",
    "For this example, we will use the values of the pixels as our feature values. This requires the 2-dimensional images be **flattened** into feature vectors. This concept is illustrated in the figure below.   \n",
    "\n",
    "<img src=\"img/FlatteningImge.JPG\" alt=\"Drawing\" style=\"width:200px; height:100px\"/>\n",
    "<center>Flattening an image to a feature vector</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9349d",
   "metadata": {},
   "source": [
    "> **Exercise 4-2:** You will now flatten the the $28 \\times 28$ images to feature vectors. Do the following:    \n",
    "> 1. Print the shape of the training image array, noticing that each image is a 2-dimensional sub-array.   \n",
    "> 2. Flatten the images to an array of 60,000 rows using [numpy.reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html). The image arrays are 8 bit integers. Convert them to floating point in the range $[0.0 - 1.0]$, which will normalize the feature values.    \n",
    "> 3. Print the shape of the flattened image array.   \n",
    "> 4. Apply the same transformations to the test image array and print the shape of the resulting array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d27364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below for the test images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726561b5",
   "metadata": {},
   "source": [
    "> Examine the dimensions of the flattened arrays. How many features will your model have? Your answer should show a simple numeric calculation.    \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272c93b",
   "metadata": {},
   "source": [
    "> **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648ed82",
   "metadata": {},
   "source": [
    "It can be instructive to look at the feature matrix. Execute the code in the cell below and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_sample(img, nrows=512):\n",
    "    fig, ax = plt.subplots(figsize=(15,9))\n",
    "    p = ax.imshow(img[:nrows,:])\n",
    "    plt.ylabel('Flattened image number')\n",
    "    plt.xlabel('Features')\n",
    "    plt.title('Flattened images')\n",
    "    cb = plt.colorbar(p)\n",
    "    _=cb.set_label('Intensity')\n",
    "    \n",
    "plot_feature_sample(train_images)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d690f",
   "metadata": {},
   "source": [
    "> **Exercise 4-3:** Examine the feature columns in the array displayed above. Notice the differing ranges of values in the features. What does this tell you about the differing information content of the features? In other words, which of these features might you expect to be predictive or not of the digit categories? Your answer need only be 1 to 3 well chosen sentences.           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8efaef",
   "metadata": {},
   "source": [
    "> **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e35d9",
   "metadata": {},
   "source": [
    "The significant number of uninformative features or pixel locations can lead to problems with model generalization. The coefficients computed for these uninformative features are unlikely to improve model performance. For example, consider that a bit of noise in some images presented to the classifier in production can lead to a high probability of erroneous classifications. \n",
    "\n",
    "There are a number of methods we could use to deal with the uninformative features, or pixel locations, in the image data. Transformation such as principle component analysis (PCA) can be effective in such situations. Here, we will take a more direct approach and filter features with close to zero variance. The code in the cell below does this by the following steps:  \n",
    "1. A feature variance filter is trained using [sklearn-feature-selection-variancethreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn-feature-selection-variancethreshold). Notice that we fit on the training data alone, not the test data, to prevent information leakage. \n",
    "2. The transformation is applied independently to the training images and test images.  \n",
    "3. A plot of the first 512 rows of the filtered training data is created and the resulting shape is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedeafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "var_threshold = VarianceThreshold(0.05).fit(train_images)\n",
    "train_images = var_threshold.transform(train_images)\n",
    "test_images = var_threshold.transform(test_images)\n",
    "\n",
    "\n",
    "plot_feature_sample(train_images)   \n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce5110",
   "metadata": {},
   "source": [
    "> **Exercise 4-4:** Compare the dimensionality and the information content of the filtered features to the original feature set. Does it appear that the information density of the remaining features is high compared to the original? Your answer need only be 1 to 3 well chosen sentences.              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a4977",
   "metadata": {},
   "source": [
    "> **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58389f",
   "metadata": {},
   "source": [
    "## A Linear Model        \n",
    "\n",
    "With the feature arrays prepared, it is time to construct the machine learning model. The code in the cell below defines the linear **logistic regression** model object and fits it to the training data. Here we use the Scikit-Learn [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) function. The model definition has several key aspects:   \n",
    "- L2 regularization with a hyperparameter $C = 1.0$.  \n",
    "- Since there are 10 categories of digits, the multinomial probability distribution is used.    \n",
    "- An efficient solver for the system of linear equations is selected.    \n",
    "\n",
    "The `fit` method with the arguments of the model (feature) matrix and the label vector.  \n",
    "\n",
    "If you are just learning to use Scikit-Learn it is useful to know that the general approach is used for all machine learning models available in the package. A model object is defined including the values of hyperparameters. A fit method is used to compute model parameters or weights. You can find a [Getting Started Guide](https://scikit-learn.org/stable/getting_started.html) in the Scikit-Learn documentation.   \n",
    "\n",
    "Now, execute the code in the cell below to create a model object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearClassifier = sklm.LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver ='newton-cg').fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56e0d9",
   "metadata": {},
   "source": [
    "> **Exercise 4-5:** The logistic regression model computes probabilities each of the categories for each case. You will now investigate an example by the following steps:    \n",
    "> 1. Apply the `predict_proba` method with the test images to the trained classifier method. \n",
    "> 2. Display the first 10 rows of the resulting array of probabilities.    \n",
    "> 3. Sum the probabilities of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b374a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below to sum probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edba41",
   "metadata": {},
   "source": [
    "> Answer the following questions in 1 to 3 well chosen sentences:  \n",
    "> 1. Examine the probabilities of the categories for each of the 10 cases. Is there generally a category with the highest probability? Are there cases where another cases has a reasonably high probability?   \n",
    "> 2. Given your answers to the foregoing question, do you expect this classifier to make errors in identifying the categories?   \n",
    "> 3. Are these proper probability distributions, in the sense that they sum to 1.0 for each case?  \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b3e09",
   "metadata": {},
   "source": [
    "> **Answers:**     \n",
    "> 1.    \n",
    "> 2.   \n",
    "> 3.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f72db",
   "metadata": {},
   "source": [
    "While it is useful to understand how the linear model algorithm computes probabilities for the categories of digits, for most applications we really only want to know the most probable category. The algorithm is quite simple; pick the category with the highest probability. Scikit-Learn provides the `predict` method that computes the probabilities are returns the category with the highest probability. Execute the code in the cell below to see an example.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predictions = LinearClassifier.predict(test_images)\n",
    "class_predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b60bf8",
   "metadata": {},
   "source": [
    "## Evaluate the Model       \n",
    "\n",
    "Now that you have a model and made predictions it is time to evaluate the model. The [Scikit-Learn metrics package](https://scikit-learn.org/stable/modules/model_evaluation.html) contains numerous functions for evaluating different types machine learning models. \n",
    "\n",
    "A widely used metric for evaluating classifiers; the number of correctly classified cases divided by all cases:   \n",
    "\n",
    "$$Accuracy = \\frac{TP}{TP + FP + FN}$$    \n",
    "\n",
    "Where, $TP$ are the true positives, $FP$ are the false positives and $FN$ are the false negatives.  \n",
    "\n",
    "In this case we will focus on evaluation of the multi-class classifier. The [sklearn.metrics.accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) computes the accuracy given the actual labels and the predicted values. Execute the code in the cell below and examine the result.         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(test_labels, class_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c39f7",
   "metadata": {},
   "source": [
    "The overall accuracy of the model seems reasonably good. However, one must be extremely careful when evaluating any machine learning model. Any single metric can be quite misleading. It is good practice to look at several views of model performance.   \n",
    "\n",
    "The **confusion matrix** can be a powerful tool for evaluating classifiers. The confusion matrix is a 2-dimensional array with the label values on vertical axis and the predicted values on the horizontal axis. The count of correctly classified cases for each category are along the diagonal. Counts or incorrectly classified cases are found off the diagonal. \n",
    "\n",
    "The confusion matrix can be computed and displayed numerically. For large numbers of categories a visualization of the confusion matrix can be useful. By studying the confusion matrix one can identify many problems which would not be apparent from one to two simple metrics. For example, accuracy of a classifier might seem quite high, but it could be misclassifying all members of some category, while doing well with other categories. Only by examination of the confusion matrix can such problems be discovered.     \n",
    "\n",
    "The code in the cell does the following:  \n",
    "1. Computes and displays the confusion matrix.   \n",
    "2. Displays the log values of the confusion matrix. The logarithm is used in this case since the off-diagonal terms are quite small compared to the diagonal terms. A 1 is added to all terms to allow computation of the logarithm, adding a small but negligible bias.     \n",
    "\n",
    "Execute the code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(test_labels, class_predictions)   \n",
    "print(confusion_matrix)\n",
    "p = plt.imshow(np.log(np.divide(confusion_matrix + 1.0, np.sum(confusion_matrix, axis=1))))\n",
    "cb = plt.colorbar(p)\n",
    "_=cb.set_label('Log count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d1f49",
   "metadata": {},
   "source": [
    "Some other commonly used [performance metrics for classifiers](https://en.wikipedia.org/wiki/Precision_and_recall) are **Precision** and **Recall**:   \n",
    "\n",
    "\\begin{align}\n",
    "Recall &= \\frac{TP}{TP + FN}\\\\\n",
    "Precision &=  \\frac{TP}{TP + FP}\n",
    "\\end{align} \n",
    "\n",
    "You can think of recall as the fraction of positive cases correctly classified, also know as the **sensitivity** of the classifier. The precision or **positive predictive value** is the probability that a positive case can be correctly classified.  \n",
    "\n",
    "> **Exercise 4-6:** The confusion matrix contains the information required to compute some key performance metrics of a classifier model. For example, the **true positive** (correctly classified) cases are along the diagonal. Being careful to differentiate the false positive and false negative cases in the confusion matrix, compute and print the accuracy, recall and precision. Use the [numpy.sum](https://numpy.org/doc/stable/reference/generated/numpy.sum.html), [numpy.diagonal](https://numpy.org/doc/stable/reference/generated/numpy.diagonal.html), [numpy.triu](https://numpy.org/doc/stable/reference/generated/numpy.triu.html), and [numpy.tril](https://numpy.org/doc/stable/reference/generated/numpy.tril.html#numpy.tril) functions for operations on the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15940131",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6b281",
   "metadata": {},
   "source": [
    "> What do these values of precision and recall tell you about the performance of the classifier model? Your answer need only be 1 to 3 well chosen sentences \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccebde",
   "metadata": {},
   "source": [
    "> **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2312259",
   "metadata": {},
   "source": [
    "There is another way to view the confusion matrix, category by category. In some cases, this representation can be easier to understand and work with. It can also be used to compute category specific metrics. To see an example of this representation, execute the code in the cell below which uses the [sklearn.metrics.multilabel_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html?highlight=multilabel_confusion_matrix) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.multilabel_confusion_matrix(test_labels, ((class_predictions)))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee3f3d",
   "metadata": {},
   "source": [
    "In the same way we can compute the class-specific precision and recall from the multi-class confusion matrix using [sklearn.metrics.precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) and [sklearn.metrics.recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfa2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(test_labels)\n",
    "class_precision = metrics.recall_score(test_labels, class_predictions, unique_labels, average=None)\n",
    "class_recall = metrics.recall_score(test_labels, class_predictions, unique_labels, average=None)\n",
    "\n",
    "print('Class-specific precision')\n",
    "print(class_precision)\n",
    "print('\\nClass-specific recall')\n",
    "print(class_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469614db",
   "metadata": {},
   "source": [
    "> **Exercise 4-7:** Examine the class specific precision and recall scores. Then compute and display the average precision and recall scores for the model by creating and executing code in the cell below. The number of cases in each of the 10 classes is the same, 1000. Therefore there is no need to weight the average when you compute it in this case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376c42d",
   "metadata": {},
   "source": [
    "> Answer the following questions in 1 to 3 well chosen sentences:  \n",
    "> 1. What does the variation in the precision and recall scores of the different digit classes tell you about the performance of the classifier?   \n",
    "> 2. Average precision and recall scores are often used to summarize the performance of multi-class classifiers. In this case, do you think the summary is reasonable, or does it loose too much information? \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605330e",
   "metadata": {},
   "source": [
    "> **Answers:**\n",
    "> 1.   \n",
    "> 2.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a814b",
   "metadata": {},
   "source": [
    "> **Exercise 4-8:** To better understand the source of errors from the classifier model it is useful to examine some details of the erroneously classified cases. You will now do the following:    \n",
    "> 1. Create an index vector of the erroneously cases.     \n",
    "> 2. Print the prediction probability vectors for the first 10 incorrectly classified cases.   \n",
    "> 3. Create a a $5 \\times 5$ grid display the first 25 gray-scale erroneously classified images. Give each image display a title with the label for that image and the predicted class. *Hint,* use a large display area.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f509bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes below to display the images with predicted and label values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae41ef",
   "metadata": {},
   "source": [
    "> Answer the following questions in 1 to 3 well chosen sentences:    \n",
    "> 1. Examine the probability vectors for the 10 erroneous cases. What observation can you make about these probabilities that help explain the errors in these cases?   \n",
    "> 2. Examine the misclassified images, the label and prediction. What observation can you make about the sources of errors in these cases?  \n",
    "> **End of exercise.**     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946f673",
   "metadata": {},
   "source": [
    "> **Answers:**   \n",
    "> 1.            \n",
    "> 2.         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cfc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
